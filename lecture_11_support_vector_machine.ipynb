{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a74bc9da",
   "metadata": {},
   "source": [
    "## LECTURE 11: Support Vector Machine\n",
    "\n",
    "## course: Awfera Machine Learning\n",
    "\n",
    "## Instructor: Dr. Shazia Saqib\n",
    "\n",
    "## Student: Muhammad Shafiq\n",
    "\n",
    "____________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281187c4",
   "metadata": {},
   "source": [
    "# What is Support Vector MAchine? \n",
    "\n",
    "**Supervised Learning Alogirthm** use for classification and regression tasks. Especially powerful for binary classification.\n",
    "\n",
    "**Finds Optimal Boundary**  Deetermines the beest hyperplane that separates data with maximum margin.\n",
    "\n",
    "**Maximizes Distance** Creates the largest possible gap  between classes for better generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad155b6",
   "metadata": {},
   "source": [
    "## The SVM Analogy\n",
    "\n",
    "**Imagine a school hallway** with two groups: **Science Club** and **Art Club**. A teacher wants to place a dividing line between them.\n",
    "\n",
    "The ideal line would be **positioned in the middle**. maximizing distanced from both group.\n",
    "\n",
    "The **students closest to the line** are critical - if they move the line might need adjusstement . These represent **support vectors.** \n",
    "\n",
    "SVM finds the **optimal dividing boundary** between classes uses the closest point to determine placement **Maximizes margin** between the boundary and each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ab071",
   "metadata": {},
   "source": [
    "## Key SVM Terminology\n",
    "\n",
    "#### Hyperplane:\n",
    "A line (in 2D) plane in (3D) or higher dimmensional surface that separates classes.\n",
    "\n",
    "#### Margin:\n",
    "The distance between the hyperplance and the closest data points from each class.\n",
    "\n",
    "#### Support Vectors:\n",
    "The data points closest to the hyperplane that define the boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacdc4d1",
   "metadata": {},
   "source": [
    "## Linear vs. Non_linear Data : \n",
    "\n",
    "### **Linearly Separable**\n",
    "SVM finds a straight line to separate classes when data can be divided by a linear boundary.\n",
    "\n",
    "### **Non_linearly Seaparble**:\n",
    "When a straight line cann't separate data. SVM uses teh Kernel trick, an algorithm to perform **non-linear classification** by implicitly mapping input data into a **higher-dimentional space** without explicitly compute the transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0138fe",
   "metadata": {},
   "source": [
    "## Kernel Trick:\n",
    "\n",
    "The **kernel trick** is an essential feature of SVM. It allows the transformation of non-linear data into a higher-dimensional space, where a linear hyperplane can separate the data. For example, if data is in 2D and is not separable by a straight line, we can map it to 3D or higher-dimensional space using a kernel. This process makes it possible to classify complex, non-linearly separable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099008ed",
   "metadata": {},
   "source": [
    "## 2. **Types of Kernels in SVM**:\n",
    "\n",
    "SVM uses different kernels to handle various types of data. The kernel function transforms the input data into a higher-dimensional space to make it easier to separate using a linear decision boundary. There are several types of kernels:\n",
    "\n",
    "  - **Linear Kernel**: Suitable for linearly separable data. It draws a straight line to separate the data into different classes.\n",
    "  - **Polynomial Kernel**: Used for data that is not linearly separable but can be separated with a polynomial decision boundary.\n",
    "  - **Gaussian (RBF) Kernel**: Useful for non-linear data, creating a boundary in a higher-dimensional space to separate the classes effectively.\n",
    "  - **Sigmoid Kernel**: Based on the sigmoid function, commonly used in certain classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cca98fd",
   "metadata": {},
   "source": [
    "## **Steps in SVM Classification**:\n",
    "\n",
    " - **Plot the Data**: Visualize the data to understand its separability.\n",
    " - **Identify the Support Vectors**: Find the data points closest to the hyperplane.\n",
    " - **Calculate the Margin**: Maximize the margin between the support vectors and the hyperplane.\n",
    "  \n",
    "   Margin = 2/||w|| where ||w|| = squareroot(w12 + w22)\n",
    "\n",
    "   where w is the length of weight vector\n",
    "   \n",
    " - **Define the Hyperplane**: Use the equation w1​x+w2​y+b=0 to define the boundary.\n",
    " The equation for the hyperplane in a 2D space is:\n",
    "\n",
    "   w1​x+w2​y+b=0\n",
    "\n",
    "   Where:\n",
    "\n",
    "    - w1​ and w2 are the weights,\n",
    "    - x and  y are the features,\n",
    "    - b is the y-intercept.\n",
    " - **Classify the Data**: If the result of the equation is greater than 0, assign class +1. If less than 0, assign class -1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bfb289",
   "metadata": {},
   "source": [
    "## Hands-on Intuition\n",
    "**Plot Data:**\n",
    "         Visualize all your data points\n",
    "\n",
    "**Draw Boundary:**\n",
    "         SVM creates a boundary between classess\n",
    "\n",
    "**Find closest Points:**\n",
    "         Identify points nearst to boundary\n",
    "\n",
    "**Maximize Space:**\n",
    "         Adjust boundary for maximun margin                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb4225",
   "metadata": {},
   "source": [
    "## When to Use SVM:\n",
    "\n",
    "- **Small to Medium Datasets**: SVM is highly effective for small to medium datasets with a manageable number of features.\n",
    "- **Binary Classification**: SVM is particularly suited for binary classification problems.\n",
    "- **Performance on Noisy Data**: SVM struggles with noisy data, where the data points are not clearly separable.\n",
    "- **Feature Scaling**: It is essential to preprocess and scale the data. Without scaling, the results may be poor.\n",
    "- **Training Time:** SVM's training time can be slow, especially with large datasets or high-dimensional data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97507b65",
   "metadata": {},
   "source": [
    "## SVM Applications:\n",
    "\n",
    "SVM is widely used in various fields due to its robustness in handling high-dimensional data. Some common applications include:\n",
    "\n",
    " - **Email Filtering**: Classifying spam vs. non-spam emails.\n",
    " - **Image Recognition**: Identifying objects or faces in images.\n",
    " - **Text Categorization:** Classifying text into predefined categories (e.g., news articles). \n",
    " - **Medical Diagnosis:** Predicting disease presence based on medical data.\n",
    " - **Bioinformatics:** Classifying genes or proteins.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe27319",
   "metadata": {},
   "source": [
    "## Key Takeaways:\n",
    "\n",
    " - **Maximize the Margin**: The ultimate goal of SVM is to maximize the margin between the support vectors and the hyperplane.\n",
    " - **Support Vectors**: The data points that are closest to the hyperplane and define the boundary.\n",
    " - **Kernel Trick**: Transforms non-linear data into higher-dimensional space for linear separation.\n",
    " - **Model Performance**: SVM works best with small to medium datasets and requires proper data preprocessing, including scaling and cleaning.\n",
    " - **Applications**: SVM is widely used in applications such as email filtering, image recognition, medical diagnosis, and bioinformatics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba69fb26",
   "metadata": {},
   "source": [
    "## Implementaion of Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e516027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "SVM for Daibetes Dataset\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Step 1; import libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# Dataset URL\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "\n",
    "# Column names as per dataset description\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
    "           'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "# Print basic info\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6c8414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking for missing Values\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# step 2: Handle Missing Values\n",
    "print(\"\\nChecking for missing Values\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing numerical values with the median\n",
    "df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# Fill missing catagorical values with the mode(if any)\n",
    "for col in df.select_dtypes(include=['object']):\n",
    "    df[col].fillna(df[col].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c88ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM Classifier...\n",
      "Model Accuracy:  0.75\n",
      "\n",
      "SVM classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.81       151\n",
      "           1       0.64      0.62      0.63        80\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.72      0.72      0.72       231\n",
      "weighted avg       0.75      0.75      0.75       231\n",
      "\n",
      "\n",
      "SVM confusion matrix: \n",
      "[[123  28]\n",
      " [ 30  50]]\n"
     ]
    }
   ],
   "source": [
    "# step 3: Prepare Data\n",
    "X = df.drop(columns=['Outcome'])\n",
    "y = df['Outcome']\n",
    "\n",
    "# step 4: Apply standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 5: split dat into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# step 6: train a support vector machine classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "print(\"\\nTraining SVM Classifier...\")\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# step 7: model evaluation for svm\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"Model Accuracy: {svm_accuracy: .2f}\")\n",
    "\n",
    "print(\"\\nSVM classification report: \")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"\\nSVM confusion matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6445fb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
