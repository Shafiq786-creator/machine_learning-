{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a54d5ba0",
   "metadata": {},
   "source": [
    "# **7 Days Data Integration Course**\n",
    "\n",
    "# **Course** : Machine Learning \n",
    "\n",
    "# **Day 1:** Introduction to Data Integration\n",
    "\n",
    "# **Student**: Muhammad Shafiq\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5af27f",
   "metadata": {},
   "source": [
    "## **ðŸ“… Day 1: Introduction to Data Integration**\n",
    "\n",
    "Weâ€™ll break it down into 4 sections:\n",
    "\n",
    "- 1. What is Data Integration?\n",
    "\n",
    "- 2. Why is it important in real ML/AI projects?\n",
    "\n",
    "- 3. Types of data sources we integrate\n",
    "\n",
    "- 4. Real-World Example: Combine data from 3 sources (Sales + Customers + Logs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05494e9",
   "metadata": {},
   "source": [
    "#### **Data Integration**\n",
    "\n",
    "Data Integration is the process of combining data from multiple heterogeneous sources into a unified consistent, and useful format.\n",
    "\n",
    "These data sources might have:\n",
    "\n",
    "- Different formats(CSV, JSON, API, SQL)\n",
    "- Different schemas(cloumns names/types)\n",
    "- Different granularities(daily logs vs.monthly reports)\n",
    "\n",
    "### **Why is integration even needed?**\n",
    "\n",
    "Because **no useful ML/AI** system runs on isolated data.\n",
    "\n",
    "Imagine a customer support AI:\n",
    "\n",
    "- Needs customer profiles (SQL)\n",
    "\n",
    "- Also needs chat history (JSON)\n",
    "\n",
    "- Also needs purchase data (CSV)\n",
    "\n",
    "To train a model on customer satisfaction, you must combine all 3 sources â†’ then clean, then model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d846ae",
   "metadata": {},
   "source": [
    "### **Real Business Logic**\n",
    "\n",
    "\n",
    "| Use Case                | Data Sources to Integrate                                   |\n",
    "| ----------------------- | ----------------------------------------------------------- |\n",
    "| Predict customer churn  | CRM (SQL) + Transaction history (CSV) + Support logs (JSON) |\n",
    "| Detect fraud            | Bank transactions (SQL) + Device logs (JSON)                |\n",
    "| AI healthcare assistant | Patient records (Excel) + Sensor data (API)                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde291ee",
   "metadata": {},
   "source": [
    "**Technical Reason:**\n",
    "\n",
    "ML Models donâ€™t know about multiple files or databases.\n",
    "They only understand one final cleaned DataFrame or tensor. You have to integrate first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24869e95",
   "metadata": {},
   "source": [
    "### **Types of Data Sources in Integration**\n",
    "\n",
    "| Format      | Description               | Example                  |\n",
    "| ----------- | ------------------------- | ------------------------ |\n",
    "| CSV / Excel | Flat file, tabular        | sales.csv, data.xlsx     |\n",
    "| JSON / XML  | Semi-structured, nested   | API responses, logs      |\n",
    "| SQL DB      | Structured, fast queries  | customer\\_db, orders\\_db |\n",
    "| API         | Live source, dynamic      | weather API, stock API   |\n",
    "| NoSQL       | Semi-structured, big data | MongoDB, Firebase        |\n",
    "| Logs        | Time-based, unstructured  | system logs, clickstream |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a4425",
   "metadata": {},
   "source": [
    "### **Load all files into pandas**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90581b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f761bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   customer_id     name  age                  email\n",
      "0         1001  Jeffrey   58  tashabecker@morse.net\n",
      "1         1002   Joseph   25      shill@delgado.org\n",
      "2         1003    David   19       smorse@yahoo.com\n",
      "3         1004   Thomas   35        chad33@shah.net\n",
      "4         1005    Kevin   33    tmartinez@gmail.com\n",
      "   order_id  customer_id   amount\n",
      "0      5935         1073  4443.65\n",
      "1      5322         1028  3449.47\n",
      "2      5405         1083  2564.83\n",
      "3      5271         1018  1609.82\n",
      "4      5574         1069  1682.34\n",
      "   log_id  customer_id  action            timestamp\n",
      "0       1         1043   login  2025-07-15 00:10:19\n",
      "1       2         1099  logout  2025-08-04 12:57:12\n",
      "2       3         1017    view  2025-07-29 15:44:17\n",
      "3       4         1082     buy  2025-07-31 10:50:51\n",
      "4       5         1034   login  2025-07-23 13:40:29\n"
     ]
    }
   ],
   "source": [
    "# load csv\n",
    "customers_df = pd.read_csv('dataset/customers_2.csv')\n",
    "logs_df = pd.read_csv('dataset/activity_logs_2.csv')\n",
    "\n",
    "# laod json\n",
    "orders_df = pd.read_json('dataset/orders_2.json')\n",
    "\n",
    "# preview\n",
    "print(customers_df.head())\n",
    "print(orders_df.head())\n",
    "print(logs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e482699",
   "metadata": {},
   "source": [
    "### **Merge all 3 dataset using `customer_id`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b40488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     customer_id     name  age                           email  order_id  \\\n",
      "0           1001  Jeffrey   58           tashabecker@morse.net       NaN   \n",
      "1           1002   Joseph   25               shill@delgado.org    5566.0   \n",
      "2           1003    David   19                smorse@yahoo.com       NaN   \n",
      "3           1004   Thomas   35                 chad33@shah.net       NaN   \n",
      "4           1005    Kevin   33             tmartinez@gmail.com    5069.0   \n",
      "..           ...      ...  ...                             ...       ...   \n",
      "131         1097    Marie   43          rhernandez@hotmail.com    5323.0   \n",
      "132         1098  Michael   35  brittanywashington@hotmail.com    5512.0   \n",
      "133         1098  Michael   35  brittanywashington@hotmail.com    5070.0   \n",
      "134         1099   Brooke   22         hhorne@dunn-edwards.com       NaN   \n",
      "135         1100   Samuel   31         bradleypeters@gmail.com       NaN   \n",
      "\n",
      "      amount  \n",
      "0        NaN  \n",
      "1    3561.28  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4    4368.36  \n",
      "..       ...  \n",
      "131  4710.80  \n",
      "132  1303.93  \n",
      "133  2897.18  \n",
      "134      NaN  \n",
      "135      NaN  \n",
      "\n",
      "[136 rows x 6 columns]\n",
      "     customer_id     name  age                           email  order_id  \\\n",
      "0           1001  Jeffrey   58           tashabecker@morse.net       NaN   \n",
      "1           1002   Joseph   25               shill@delgado.org    5566.0   \n",
      "2           1003    David   19                smorse@yahoo.com       NaN   \n",
      "3           1004   Thomas   35                 chad33@shah.net       NaN   \n",
      "4           1004   Thomas   35                 chad33@shah.net       NaN   \n",
      "..           ...      ...  ...                             ...       ...   \n",
      "184         1098  Michael   35  brittanywashington@hotmail.com    5512.0   \n",
      "185         1098  Michael   35  brittanywashington@hotmail.com    5070.0   \n",
      "186         1099   Brooke   22         hhorne@dunn-edwards.com       NaN   \n",
      "187         1099   Brooke   22         hhorne@dunn-edwards.com       NaN   \n",
      "188         1100   Samuel   31         bradleypeters@gmail.com       NaN   \n",
      "\n",
      "      amount  log_id  action            timestamp  \n",
      "0        NaN     NaN     NaN                  NaN  \n",
      "1    3561.28    13.0     buy  2025-07-15 03:49:26  \n",
      "2        NaN     NaN     NaN                  NaN  \n",
      "3        NaN    47.0    view  2025-07-09 03:13:36  \n",
      "4        NaN    69.0    view  2025-07-15 02:56:16  \n",
      "..       ...     ...     ...                  ...  \n",
      "184  1303.93     NaN     NaN                  NaN  \n",
      "185  2897.18     NaN     NaN                  NaN  \n",
      "186      NaN     2.0  logout  2025-08-04 12:57:12  \n",
      "187      NaN    76.0  logout  2025-07-28 23:51:22  \n",
      "188      NaN    37.0    view  2025-07-08 01:32:06  \n",
      "\n",
      "[189 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "cust_orders = pd.merge(customers_df, orders_df, on='customer_id', how='left')\n",
    "\n",
    "print(cust_orders)\n",
    "\n",
    "# merge cust_orders + acitivity\n",
    "final_df = pd.merge(cust_orders, logs_df, on='customer_id', how='left')\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9698cf3",
   "metadata": {},
   "source": [
    "### **Your Homework**:\n",
    "\n",
    "Create your own mock datasets:\n",
    "\n",
    "- One CSV (students info)\n",
    "\n",
    "- One JSON (exam scores)\n",
    "\n",
    "- One log (CSV) for website visits\n",
    "\n",
    "Then integrate all 3 and show student_id, name, score, last_visit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd207f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student_id                name  age                          email\n",
      "0        2001       Tyler Watkins   21  angelatorres@burns-benson.com\n",
      "1        2002  Mr. Jonathan Lewis   21        williamsnancy@white.com\n",
      "2        2003      Michael Garcia   20           rossdaniel@gmail.com\n",
      "3        2004       Heidi Johnson   22            cbenson@hotmail.com\n",
      "4        2005      Scott Thompson   21             pburnett@yahoo.com\n",
      "   exam_id  student_id  subject  score\n",
      "0    10445        2023  Science  73.11\n",
      "1    10941        2069  History  62.54\n",
      "2    10845        2094  Science  52.56\n",
      "3    10251        2012  Science  91.71\n",
      "4    10249        2097  History  69.89\n",
      "   log_id  student_id           action            timestamp\n",
      "0       1        2031     download_pdf  2025-08-03 05:35:31\n",
      "1       2        2064            login  2025-07-09 09:34:45\n",
      "2       3        2075           logout  2025-07-16 02:22:01\n",
      "3       4        2019            login  2025-07-14 17:20:17\n",
      "4       5        2030  view_assignment  2025-07-26 16:46:32\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "student_df = pd.read_csv(\"dataset/students.csv\")\n",
    "exam_df = pd.read_json(\"dataset/exam_scores.json\")\n",
    "log_df = pd.read_csv(\"dataset/website_logs.csv\")\n",
    "\n",
    "print(student_df.head())\n",
    "print(exam_df.head())\n",
    "print(log_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e964e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student_id                name  age                          email  \\\n",
      "0        2001       Tyler Watkins   21  angelatorres@burns-benson.com   \n",
      "1        2002  Mr. Jonathan Lewis   21        williamsnancy@white.com   \n",
      "2        2003      Michael Garcia   20           rossdaniel@gmail.com   \n",
      "3        2004       Heidi Johnson   22            cbenson@hotmail.com   \n",
      "4        2005      Scott Thompson   21             pburnett@yahoo.com   \n",
      "\n",
      "   exam_id  subject  score  \n",
      "0      NaN      NaN    NaN  \n",
      "1  10467.0  English   58.7  \n",
      "2      NaN      NaN    NaN  \n",
      "3      NaN      NaN    NaN  \n",
      "4      NaN      NaN    NaN  \n",
      "   student_id                name  age                          email  \\\n",
      "0        2001       Tyler Watkins   21  angelatorres@burns-benson.com   \n",
      "1        2002  Mr. Jonathan Lewis   21        williamsnancy@white.com   \n",
      "2        2002  Mr. Jonathan Lewis   21        williamsnancy@white.com   \n",
      "3        2003      Michael Garcia   20           rossdaniel@gmail.com   \n",
      "4        2004       Heidi Johnson   22            cbenson@hotmail.com   \n",
      "\n",
      "   exam_id  subject  score  log_id        action            timestamp  \n",
      "0      NaN      NaN    NaN     NaN           NaN                  NaN  \n",
      "1  10467.0  English   58.7    12.0  download_pdf  2025-07-08 11:02:30  \n",
      "2  10467.0  English   58.7    45.0         login  2025-07-13 17:24:19  \n",
      "3      NaN      NaN    NaN    41.0  download_pdf  2025-07-25 20:14:04  \n",
      "4      NaN      NaN    NaN     NaN           NaN                  NaN  \n"
     ]
    }
   ],
   "source": [
    "# integrate them\n",
    "student_exam = pd.merge(student_df, exam_df, on='student_id', how='left')\n",
    "print(student_exam.head())\n",
    "\n",
    "final_info = pd.merge(student_exam,log_df, on='student_id', how='left' )\n",
    "print(final_info.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_integration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
